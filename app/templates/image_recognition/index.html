{% extends "base.html" %}

{% block app_content %}

<div class="">

    <!-- Modal page info -->
    <div class="modal fade" id="PageModalDescription" tabindex="-1" role="dialog">
    <div class="modal-dialog modal-xl modal-dialog-centered" role="document">
        <div class="modal-content">
          <div class="modal-header">
            <p class="modal-title" style="font-size: calc(12px + 1.1vw); font-weight: bold">{{ _('Image recognition') }}</p>
            <button type="button" class="close" data-dismiss="modal" aria-label="Close">
              <span aria-hidden="true">&times;</span>
            </button>
          </div>
          <div class="modal-body text-justify" style="font-size: 0.8rem; line-height: 1.1; font-family: Arial">
              <p class="">{{ _('The term ') }}
                  <a href="https://en.wikipedia.org/wiki/Outline_of_object_recognition">{{ _('"image recognition"') }}</a>
                  {{ _('is associated with') }}
                  <a href="https://en.wikipedia.org/wiki/Computer_vision">{{ _('"computer vision"') }}</a>
                  {{ _('(CV), which is a comprehensive shortcut for the process of teaching computers to "see" as
                  people, and') }}
                  <a href="https://en.wikipedia.org/wiki/Digital_image_processing">{{ _('"image processing"') }}</a>
                  {{ _(', which is a universal term for computers that perform certain
                  calculations and transformations on image data. Image recognition is a subsection of computer
                  vision in which, using various algorithms and techniques, certain objects can be recognized in
                  an image.') }}
              </p>
              <p> {{ _('On this page,') }}
                  <a href="https://en.wikipedia.org/wiki/Artificial_neural_network">{{ _('artificial neural networks') }}</a>
                  {{ _('(ANN), in particular') }}
                  <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">{{ _('convolutional networks') }}</a>
                  {{ _('(CNN), which over the past few years have proven their absolute advantage over other image
                  recognition techniques, are used for image recognition.') }}
              </p>
              <p> {{ _('The first widely known convolutional neural network is') }}
                  <a href="https://en.wikipedia.org/wiki/AlexNet">{{ _('AlexNet') }}</a>
                  {{ _(', which in 2012 achieved top-5 recognition error of 15.3&#37,
                  thereby surpassing other computer vision algorithms at that time by more than 10&#37. Since then,
                  CNN have received significant development. The changes and improvements concerned mainly the
                  ways of connecting the network layers to each other, various normalization methods, reducing
                  the computational power required for operation, etc., but their main principle - convolution
                  remained the same.') }}
              </p>
              <p> {{  _('The fundamental of artificial neural networks is that their functioning requires initial training on a specific data set, which is limited to a certain number of predefined classes of images that the network will be able to recognize. Classes of objects that were not in the training data, the network will not be able to recognize. Imagine that you have never seen, for example, a giraffe in your life. Never seen, - neither in pictures, nor in real life. And then someone shows you a giraffe and ask "what is this?" What will you answer? Most likely, you say that this object is most similar to something..., to something that you saw earlier. Artificial neural networks operate in a similar way.') }}
              </p>
              <p> {{ _('This subsection discusses some of different CNN models trained on the IMAGENET1000 dataset, which includes objects of 1000 different classes, such as, for example, an airplane, a dam, meadows, various animals, various breeds of dogs and much more. Thus, the models used here can, with a certain probability, recognize an object in the image if it belongs to these 1000 classes, or determine which known class it is closest to.') }}
              </p>
              <p> {{ _('On this page there is an area for previewing the image, to the right of which is the area of ​​"prediction", which shows the 5 most likely objects in the image, according to the used model. You can try to click on a prediction bars to online translate it into your local language (powered by Yandex translate). You can upload your image with "Browse" button or paste the image from the clipboard. You can also switch the models of neural networks using the buttons in the bottom. The prediction results will change automatically.') }}
              </p>
              <p style="color: red; font-weight: bold"> {{ _('Please note that this demo site is not hosted on a high-performance computer, so it will take some time to operate, be patient.') }}
              </p>
          </div>
        </div>
    </div>
    </div>
    <!-- /Modal page info -->

    <!-- Brief page description on top-->
    <div class="card" style="padding: 0; margin: 5px 0 0 0; ">
        <div class="card-body" style="padding: 5px 5px 0 5px; margin: 5px 5px -5px 5px;">
<!--        <button class="btn btn-primary fa fa-question-circle fa-siz fa-2x" id="page-help" style="float: right; padding: 0; margin: 0px 0px 3px 10px;"> </button>  -->
        <h6 class="text-justify" id="description-text" style="font-family: Yanone Kaffeesatz; font-size: calc(10px + 0.5vw) ;cursor: pointer;  line-height: 0.95;">
            {{ _('Select a file or paste an image from the clipboard and see what it is with what probability (according to the deep neural networks). You can switch between models using the corresponding buttons below. ') }}
            <span style="color: red">{{ _('You can click this message for more details.') }} </span>
        </h6>
        </div>
    </div>
    <!-- /Brief page description on top-->

    <!-- Input form -->
    <form style="display: block; position: relative;margin: 1rem 0" id="upload-file" method="post" enctype="multipart/form-data">
      <div class="block-input-modal" style=""></div> <!-- Block input form -->
        <div class="d-flex" style="justify-content: center; justify-items: center; ">
        <label class="btn btn-outline-primary text-nowrap" style="" for="inputfile" id="inputlabel1"> {{ _('Browse file') }} </label>
        <input id="inputfile" type="file" style="display: none;" name="file" class="form-control-file"  accept="image/*">
        <input type="url" id="inputurl" class="form-control" style="padding: 0; height: auto" name="img-url" placeholder="{{ _('or paste image here') }}" />

        <label class="btn btn-outline-primary" style="" for="camera-input" id="inputlabel2"> <span data-feather="camera"></span></label>
        <input id="camera-input" type="file" style="display: none;" accept="image/*" capture="camera" />
      </div>
  </form>
    <!-- /Input form -->

    <!-- Preview and predict form -->
  <div class="d-flex flex-row justify-content-around preview-predict-form" style="">
     <div class="block-input-modal" style="position: absolute; width: 100%; height: 100%"> <!-- Block input form -->
         <div style="position: absolute; top: 50%; left: 50%; transform: translateX(-50%) translateY(-50%); font-size: 3vw; font-weight: 600 ;">
             <span class="spinner-grow spinner-grow-lg" style="vertical-align: middle" role="status" aria-hidden="true"></span>
             <span class="wait-text-blinking">{{ _('Please wait') }}</span>
         </div>
     </div>
    <img class="rounded" src="" id="imgpreview" alt="" style="object-fit: contain;height: 100%; max-width: 67%">

    <!-- Prediction bars  -->
    <div style="width: 30%; margin-left: 1%;">
        <div class="" id="class-bars" style="position: absolute; overflow-y: auto; overflow-x: auto">
        <div class="progress-bar pred-item" role="progressbar" style="opacity: 0 ;background-color: green;">  </div>
        <div class="progress-bar pred-item" role="progressbar" style="opacity: 0 ;background-color: dodgerblue;">  </div>
        <div class="progress-bar pred-item" role="progressbar" style="opacity: 0 ;background-color: yellow;">  </div>
        <div class="progress-bar pred-item" role="progressbar" style="opacity: 0 ;background-color: chocolate;">  </div>
        <div class="progress-bar pred-item" role="progressbar" style="opacity: 0 ;background-color: red;">  </div>
        </div>
    </div>
  </div>
    <!-- /Preview and predict form -->

    <!-- Model change form -->
    <div class="d-block" style="position: relative;">
        <div class="f-flex block-input-modal" style=" "></div> <!-- Block models change -->
        <ul class="nav nav-pills" id="models-tab" role="tablist">
            <li class="nav-item">
                <a class="nav-link active" id="model1-tab" data-target="#model1-href" data-toggle="pill" href="./model?model=mobilenet_v2"  role="tab" aria-controls="model1-href" aria-selected="true">MobileNet</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" id="model2-tab" data-target="#model2-href" data-toggle="pill" href="./model?model=resnet34" role="tab" aria-controls="model2-href" aria-selected="false">ResNet34</a>
            </li>
            <li class="nav-item">
                <a class="nav-link" id="model3-tab" data-target="#model3-href" data-toggle="pill" href="./model?model=resnet101" role="tab" aria-controls="model3-href" aria-selected="false">ResNet101</a>
            </li>
        </ul>
        <div class="tab-content models-tab" id="models-tabContent" style="">
            <!-- MobileNet  -->
            <div class="tab-pane fade show active" id="model1-href" role="tabpanel" aria-labelledby="model1-tab">
            <div class="card">
                <div class="card-header" style="font-family: 'Russo One', sans-serif">
                    {{ _('The  model is pretrained on ') }}
                    <a href="https://en.wikipedia.org/wiki/ImageNet">ImageNet1000</a>
                    {{ _(' dataset') }}
                </div>
                <div class="card-body">
                    <p class="card-text">
                    <a href="https://arxiv.org/abs/1801.04381">MobileNetV2</a>
                    {{ _('(introduced by Google in 2018) is an improved version of MobileNetV1, introduced a year earlier. It has a small size, low required computation power while maintaining acceptable accuracy. Thanks to these properties, this model can be used on mobile devices, providing consistent speed and accuracy. MobileNetV2 is a convolutional neural network that uses residual connections between blocks. The key features of the model are the following:') }}
                    </p>
                     <ul>
                        <li> {{ _('the absence of the max pulling block between layers that is usual for convolution networks; instead, convolution with step 2 is used;') }} </li>
                        <li> {{ _('regular convolutions replaced by “depthwise convolutions”, the essence of which is to use a separate convolution filter for each input channel (feature map); number of output channels in this case is equal to number of input channels;') }} </li>
                        <li> {{ _('the depthwise convolution is followed by a pointwise convolution. This really is the same as a regular convolution but with a 1×1 kernel.') }} </li>
                    </ul>
                    <p>{{ _('A regular convolution does both filtering and combining in a single go, but with a depthwise separable convolution these two operations are done as separate steps.') }}
                    </p>
                    <p>{{ _('Main MobileNetV2 bulding block called "bottleneck" and consist of 1x1 "extension" pointwise convolution layer, 3x3 depthwise convolution layer and 1x1 "projection" pointwise convolution layer. The full MobileNet V2 architecture, then, consists of 17 of these building blocks in a row. There are residual connections between these blocks. This is followed by a regular 1×1 convolution, a global average pooling layer, and a fully connected classification layer. The very first block is slightly different, it uses a regular 3×3 convolution with 32 channels instead of the expansion layer. Some depthwise convolutions have a stride of 2 to reduce the dimension of feature maps, in this case no residual connection is used in this layer. MobileNetV2 uses batch normalization after all layers and Relu6 as an activation function. ') }}
                    </p>
                    <p>{{ _('You can read more about this model') }}
                    <a href="https://machinethink.net/blog/mobilenet-v2/">{{ _('here') }}</a>
                    {{ _('and') }}
                    <a href="https://towardsdatascience.com/review-mobilenetv2-light-weight-model-image-classification-8febb490e61c">{{ _('here') }}</a>
                    .
                    </p>
                </div>
            </div>
        </div>
            <!-- Resnet34  -->
            <div class="tab-pane fade" id="model2-href" role="tabpanel" aria-labelledby="model2-tab">
            <div class="card">
                <div class="card-header" style="font-family: 'Russo One', sans-serif">
                    {{ _('The  model is pretrained on ') }}
                    <a href="https://en.wikipedia.org/wiki/ImageNet">ImageNet1000</a>
                    {{ _(' dataset') }}
                </div>
                <div class="card-body">
                    <p class="card-text">
                    {{ _('With the advent of such models of artificial neural networks as') }}
                    <a href="https://en.wikipedia.org/wiki/AlexNet">AlexNet</a>
                    {{_('and')  }}
                    <a href="https://arxiv.org/pdf/1409.1556.pdf">VGG</a>
                    {{ _(', it became clear that the deeper the network (the more layers it has), the more accuracy you can get from it. At the same time, the deeper the network, the harder to train it') }}
                    <a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem">(Vanishing gradient_problem)</a>
                    {{ _('. As a method of dealing with this problem in 2015 a Microsoft research group presented a neural network with  residual connections named') }}
                    <a href="https://arxiv.org/pdf/1512.03385.pdf">ResNet</a>
                    {{ _('In this model the input of each block is directly connected to the output. This approach can significantly reduce the effect of a gradient vanishing at learning and make it possible to increase the number of network layers, thereby increasing accuracy.') }}
                    </p>
                    <p>{{ _(' The ResNet family has several varieties in terms of the number of layers. The least deep model is Resnet18, the most is ResNet152. All ResNet networks have an input convolutional layer with a 7x7 kernel, a max-pooling layer, then 4 "complex" layers, which include several ResNet blocks, this complex layers differ from each other in the number of channels processed in the blocks included in them. This all is followed by  average pooling layer and a fully connected classification layer. In the Resnet18 and ResNet 34 networks, the "basic" ResNet block is used, that consist of two convolutional layers with a 3x3 core. In Resnet50 and deeper networks, to reduce the required computation complexity, a bottleneck block is used. The bottleneck block consist of three convolutional layers with 1x1, 3x3, 1x1 kernels respectively . Batch normalization is used after all convolutional layers of the network and Relu is used as an activation function.') }}
                    </p>
                    <p>
                    {{ _('More details can be found') }}
                    <a href="https://en.wikipedia.org/wiki/Residual_neural_network">{{ _('here') }}</a>
                    {{ _('and') }}
                    <a href="https://towardsdatascience.com/a-deeper-dive-into-residual-learning-d92e0aaa8b32">{{ _('here') }}</a>
                    </p>
                </div>
            </div>
        </div>
            <!-- Resnet101  -->
            <div class="tab-pane fade" id="model3-href" role="tabpanel" aria-labelledby="model3-tab">
            <div class="card">
                <div class="card-header" style="font-family: 'Russo One', sans-serif">
                    {{ _('The  model is pretrained on ') }}
                    <a href="https://en.wikipedia.org/wiki/ImageNet">ImageNet1000</a>
                    {{ _(' dataset') }}
                </div>
                <div class="card-body">
                    <p class="card-text">
                    {{ _('With the advent of such models of artificial neural networks as') }}
                    <a href="https://en.wikipedia.org/wiki/AlexNet">AlexNet</a>
                    {{_('and')  }}
                    <a href="https://arxiv.org/pdf/1409.1556.pdf">VGG</a>
                    {{ _(', it became clear that the deeper the network (the more layers it has), the more accuracy you can get from it. At the same time, the deeper the network, the harder to train it') }}
                    <a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem">(Vanishing gradient_problem)</a>
                    {{ _('. As a method of dealing with this problem in 2015 a Microsoft research group presented a neural network with  residual connections named') }}
                    <a href="https://arxiv.org/pdf/1512.03385.pdf">ResNet</a>
                    {{ _('In this model the input of each block is directly connected to the output. This approach can significantly reduce the effect of a gradient vanishing at learning and make it possible to increase the number of network layers, thereby increasing accuracy.') }}
                    </p>
                    <p>{{ _(' The ResNet family has several varieties in terms of the number of layers. The least deep model is Resnet18, the most is ResNet152. All ResNet networks have an input convolutional layer with a 7x7 kernel, a max-pooling layer, then 4 "complex" layers, which include several ResNet blocks, this complex layers differ from each other in the number of channels processed in the blocks included in them. This all is followed by  average pooling layer and a fully connected classification layer. In the Resnet18 and ResNet 34 networks, the "basic" ResNet block is used, that consist of two convolutional layers with a 3x3 core. In Resnet50 and deeper networks, to reduce the required computation complexity, a bottleneck block is used. The bottleneck block consist of three convolutional layers with 1x1, 3x3, 1x1 kernels respectively . Batch normalization is used after all convolutional layers of the network and Relu is used as an activation function.') }}
                    </p>
                    <p>
                    {{ _('More details can be found') }}
                    <a href="https://en.wikipedia.org/wiki/Residual_neural_network">{{ _('here') }}</a>
                    {{ _('and') }}
                    <a href="https://towardsdatascience.com/a-deeper-dive-into-residual-learning-d92e0aaa8b32">{{ _('here') }}</a>
                    </p>
                </div>
            </div>
        </div>
        </div>
    </div>
    <!-- /Model change form -->
</div>


{% endblock %}


